{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Machine Learning Algorithms with Microbiome dataset\n",
    "---\n",
    "\n",
    "\n",
    "## Brian Nohomovich and Nat Hawkins\n",
    "### 21 April, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Acute gastroenteritis is a major disease burden in the United States and the world over. More than 179 million people will have gastroenteritis in the United States alone each year. Previous studies have identified changes (dysbiosis) in the microbiome of patients with gastroenteritis and associated them with disease severity. The traditional methodology to study the microbiome is time-consuming, a lack of standardized analysis and requires a level of expertise. Machine learning algorithms have not been routinely used in microbiome data. However, they offer a lot of utility in being able to answer complex questions by accessing and implementing a working knowledge of more data than can be traditionally compared all at once by hand. The algorithms offer a way of teaching a computer to formulate its own diagnosis parameters for predicting outcome classes based on features, which is largely applicable to microbiome data. Further, there is no recommendation on what approach to utilize. Here we present a standardized approach using machine learning algorithms that does not require a sophisticated level of expertise and can be run on any microbiome dataset if formatted appropriately. We sought to classify the microbial community pertrubations associated with gastroenteritis and examine how our algorithms compared to the predicted dysbiosis in the literature. Our results indicate that machine learning algorithms can be utilized to classify health status of individuals based on microbiome data and clinical presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Gastroenteritis is a major cause of death and debilitation worldwide. 179 million acute cases of gastroenteritis occur in the United States each year (1). Bacterial agents are only identified in 50% of these cases (2). In fact, recent studies suggest that culture-positive identification may be lower. A recent study of 196 hospitalized cases found that only 10% were culture-positive for a causative agent (3). To date, culturing bacteria remains the gold standard of pathogen identification and treatment options. The Human Microbiome Project (4) was integral in development of metagenomic approaches. Previous findings involving metagenomics with 16s sequencing data have identified elevations in Proteobacteria in acute gastroenteritis patients (5). Proteobacteria is a phylum that has the pro-inflammatory family Enterobacteriaceae. Enterobacteriaceae consist of major enteric pathogens like Escherichia, Klebsiella, Salmonella, and Campylobacter. Findings of elevated Proteobacteria and inflammation have been found in numerous diseases including infections (6–8) and autoimmune disorders (9–12). These findings define a model of dysbiosis (alteration) of the microbiome in a disease state (13). Sequencing the 16s region is only capable of identifying metagenomes at the genus level. Directly identifying causative agents at the species or strain level is necessary to define the disease process with higher precision and identify therapeutic targets. To date, utilizing machine learning for analyzing metagenomic data with corresponding metadata has been rarely attempted. A large-scale study utilized 2424 publicly available metagenomic samples from eight studies and found that their model had good predictive value and identified species of bacteria associated with illness (14). The species of bacteria identified both confirmed and contrasted previous metagenomic studies. We propose using a metagenomic dataset to investigate various machine learning algorithms (15). The approach is to clean the data, apply machine learning algorithms and compare to the current standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Methods\n",
    "\n",
    "An active surveillance system was created through the Michigan Department of Human Health Services (MDHHS) Bureau of Laboratories to identify patients with enteric infections caused by Campylobacter, Salmonella, Shigella and Shiga toxin producing E. coli (STEC), as described (5). Metadata was collected from the patient at the time of submission and consists of symptoms, exposure history, antibiotic history, diet history and demographics. Over 1000 samples were collected in the study. In this proposal, 9 samples will be used consisting of individuals in the healthy, sick and follow-up states. The bacterial count data was prepared by processing the stool samples. Stool samples received from MDHHS were homogenized and centrifuged upon arrival; aliquots were stored in triplicate at -80 °C. DNA was extracted, and a single library pool was created for sequencing. Quality control of the library pool was confirmed with qPCR and DNA quantity. The library was sequenced with Illumina hiseq, and fastq files of raw reads were generated. Adaptors and low-quality reads will be removed using Trimmomatic v0.32 (20). FastQC (21) is used to read the Fastq files and generate a quality control report including poor quality reads, adaptors, and biases. Reads passing quality control (per base sequence quality > 30) are stripped of human reads by aligning to a database of the 1000 human refseq genomes from NCBI using bowtie2 (22) and samtools (23) to remove reads that match. Reads will be assembled with IDBA_UD (24). Reads and contiguous sequences (contigs) will be clustered at 97% identity over 90% length using CD-hit (19) to remove duplicates. Reads will be mapped to contigs with BWA (25). Reads will be annotated via blastx (26) against a local refseq (27) virus database using an e-value threshold of < 10-5 and 70% query coverage. MEGAN (28) will parse the local blast results. Unannotated contigs will be annotated using Kraken (29). Custom python scripts will merge the taxonomical and read counts for all contigs and samples. The dataset has features including biological and viral counts as well as clinical and lifestyle focused variables.\n",
    "\n",
    "The goals of this project are to construct computational models to better understand the key characteristics of patient’s condition and use new information to predict a patient’s health status. We propose using a select few types of computational models. First, we will use a classification method that uses the microbiological data (counts of viral and bacterial components in a patient’s sample) and some clinical features (such as symptoms) to construct a model capable of making predictions when introduced to new data. The classification method that we will be using is the Random Forest Classifier (16). The Random Forest Model is based on decision trees. Features are selected at random from the dataset and serve as nodes for the decision tree. The algorithm then sets some threshold for this feature by which the data can be divided into new branches. A new feature is then selected, and the process continues. In the end, the algorithm has a chain of logic that it can follow to distinguish one class from another. In the case of our data, we will we be building a forest of decision trees that looks at the counts of bacterial and viral components as well as clinical features and use those values to be able to classify what condition a patient is in.\n",
    "\n",
    "\n",
    "The regression model that we will be using in our analysis is Linear Regression. However, linear regression is used to create a mathemtical formulation for predicting new outputs based on inputs and not for discrete classifications. For this reason, we are using a support vector machine with a linear kernel to create functional boundaries used to distinguish classification regions from one another. The exact computational method being used is the OneVsRestClassfifer in scikit-learn. This method fits one classifier per class but fits it against every other class, which can give a general picture of the class based on the classifier, but also allow for robust multi-class classification. This algorithm operates by performing an ordinary least squares minimization but can be adapted to higher dimensional dataset. The advantage to using both methods in our analysis is that we will be able to extract feature importance from the models using the Random Forest Model,  a feature which is not so readily available with Linear Regression. The importance of a feature is determined by the weight of a feature in determining the outcome of the model. A more general definition pertaining specifically to the Random Forest Classifier is how likely is the feature to serve as a node after which point the data has been distinguished. Using this ability to extract feature importance, we will look at which features are most important in determining the outcome label of a patient. This serves as the primary goal for our project: which features can we identify as being most important from the dataset from a biological perspective in treating and identifying the risk of patients. Since Proteobacteria have been shown to have high abundance in patients with acute gastroenteritis we hypothesize that Proteobacteria will have a high feature importance. In examining this type of data in the future, we would also like to make some recommendations as to which type of analysis/model should be used. \n",
    "\n",
    "We are implementing a Logistic Regression model into our analysis as well. The reason behind this is Logistic Regression is often used for data in which the dependent variable is categorical in nature. In instances of multi-class classification, scikit-learn's Logistic Regression function actually calls the OneVsRestClassifier algorithm in order to handle the categorical classification. This is currently a standard method in this field for analyzing microbiome data (15), and we would like to include it in our work as well to see what results we can get from it.\n",
    "\n",
    "We will use the Random Forest Classifier to extract feature importances, and our Linear SVM model and Logistic regression model to get some further predictive power, but we will compare both against the outcome of a clustering method, specifically K-Means, to see which algorithm the best job of predicting a patient’s health. The reason why we are incorporating clustering into this is to see if there is any spatial form to the data that lends itself to prediction, and thus, another tool to be used in diagnosis. We will be comparing these four types of methods to see how their performances differ when doing this kind of analysis. To compare these methods, we will be splitting the data using Scikit-Learn’s train_test_split function. This function randomly samples our dataset to create two datasets. One, rightfully called the training dataset, is a subset used to build the model and train it to identify how the features of each sample lead to that sample’s labelling. The test dataset is then used to evaluate the newly built model. Since we will know what the health labels of the patients are, then we compare what the model predicts with what the official diagnosis is. The model will then be evaluated based using metrics such as the area under the receiver operating characteristic curve, or AUC, confusion matrices, summary tables, and some measures for evaluating agreement between labeling such as the adjusted rand index. To improve consistency and robustness of our models, we will also use cross validation and debiasing in training our models.\n",
    "\n",
    "For each method, confusion matrices and classification summaries will be calculated as well as AUC scores for each of the categorical outputs.\n",
    "\n",
    "Our goal is to not invent new computational methods for analyzing this kind of data, but prove that these methods can be applied to microbiome data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Discussion\n",
    "\n",
    "**Linear Support Vector Machine**\n",
    "\n",
    "The linear support vector machine does a good job of properly predicting the health status of a patient in the test data. The AUC for the _Case_ label was 0.95 and with the AUC for _Control_ and _Follow_ being closer to 0.85.\n",
    "\n",
    "![Really](../results/lin_svm.png)\n",
    "\n",
    "```\n",
    "Figure 1. Confusion Matrix of Linear Support Vector Machine.\n",
    "This figure identifies the samples in the test set and identifies their predicted and real values. For instance, their are 15 \"Sick\" samples in the test dataset. 13 of them are predicted correctly and 2 are predicted wrong (predicted as 1 healthy and 1 follow-up). \n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "AUC Case: 0.95\n",
    "AUC Control: 0.8793\n",
    "AUC Follow: 0.8378\n",
    "```\n",
    "\n",
    "**Random Forest Classifier**\n",
    "\n",
    "Our random forest model predicts the patient's health status well, but comparatively less well than the Linear SVM. No statistics were run to compare the output scores to determine significance. However, the _Case_ AUC is 0.92 and the the _Control_ and _Follow_ AUC's are around 0.80. The interesting result here comes from the feature importances. The most important feature was _Fever_, followed by _Proteobacteria_. From the literature, we expected _Proteobacteria_ to be a very important feature because it is a key determining factor in making a diagnosis. Next is _No Symptoms_, which is important because the definition of not being a _Case_ is to be symptom free, so the model identifies this as being important in making its classifications. Folllowing that is _Fermicutes_, which also based on the literature, is a bacteria that is present in an individual when they have a healthy GI track. The main takeaway from this being that the model has identified the bacteria present when someone is \"sick\" and someone is \"healthy\" as being important for making classifications. This aligns with what we expected in our results from the literature.\n",
    "\n",
    "![full_w_clinical_importances.png](../results/full_w_clinical_importances.png)\n",
    "\n",
    "```\n",
    "Figure 2. Feature Importances as determined by Random Forest Classifier.\n",
    "This figure identifies Fever, Proteobacteria and No Symptoms as the top 3 most important features. Fever and Proteobacteria abundance elevation was present in the vast majority of cases. No symptoms was present in most of the controls but not in the follow-up. The No symptom feature is probably how the classified distinguishes follow-up from control states.\n",
    "```\n",
    "\n",
    "![random_forest.png](../results/random_forest.png)\n",
    "```\n",
    "Figure 3. Confusion Matrix of Random Forest Classifier results.\n",
    "This figure identifies the samples in the test set and identifies their predicted and real values. For instance, their are 27 \"Healthy\" samples in the test dataset. 25 of them are predicted correctly and 2 are predicted wrong (predicted as 1 sick and 1 follow-up). \n",
    "```\n",
    "\n",
    "```\n",
    "AUC Case: 0.9221\n",
    "AUC Control: 0.8316\n",
    "AUC Follow: 0.7784\n",
    "```\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "Logistic Regression had comparatively high scores for AUC, similar to that of the Linear SVM. As this is a staple method in the field right now, we expected this to have comparatively high results.\n",
    "\n",
    "![log_reg.png](../results/log_reg.png)\n",
    "\n",
    "```\n",
    "Figure 4. Confusion Matrix of Logistic Regression.\n",
    "Logistic regression is a standard model used in microbiome analysis. This figure identifies the samples in the test set and identifies their predicted and real values. For instance, their are 14 \"Follow-up\" samples in the test dataset. 13 of them are predicted correctly and 1 are predicted wrong (predicted as 1 healthy). This model had the best AUC compared to the other methods so far. \n",
    "```\n",
    "\n",
    "```\n",
    "AUC Case: 0.9525\n",
    "AUC Control: 0.8819\n",
    "AUC Follow: 0.8503\n",
    "```\n",
    "\n",
    "\n",
    "It should be noted that for all models, the highest scoring AUC was for the _Case_ patients. From an ethical perspective, this is a desired outcome. We want to be able to build robust models that are capable of properly identifying when someone is sick and requires clinical attention. It's the ethical debate that a false positive is much better than a false negative. We don't want to send someone home saying that they aren't sick when in reality they need attention before their condition progresses. In that manner, all of these models do a good job of identifying the sick patients to a high degree. The _Control_ and _Follow_ are less accruately identified, with _Follow_ being the lowest consistently. This is an artifact of the data. The _Follow_ patients were suppoed to report sometime after they had been treated, but that timeframe was ambiguous. Some patients didn't report back for a couple of weeks, while others reported back a few days later. For that reason, there is a lack of consistency across the patients' conditions, and the models all pick up on this and have some trouble clearly defining the boundaries by which they are classifying the patients with.\n",
    "\n",
    "**Comparison Between Various Methods**\n",
    "\n",
    "We wanted to test not only the agreement between these methods with KMeans, but with one another as well. The adusted rand index ranges from -1 to 1, with -1 indictaing perfect backwards labeling (inverse labeling) where everything was correctly predicted but in the aboluste wrong order. For example, every _Case_ patient is predicted as _Control_, every _Control_ is predicted _Follow_, and every _Follow_ predicted _Case_. A rand index of 0 indicates no agreement, or noisey classification comparison. A 1 is a perfect agreement. In comparing our methods to KMeans, the scores are relatively low, but the highest rand index is seen in our comparisons with k = 3. This makes sense because we have three unique classes in our data, so KMeans is able to correctly identify this based on spatial distributions. However, the agreement is not very high, which indicates that there is a lot of disagreement between how KMeans assigns the patients to centroids and how the models draw dividing regions of classification with the patients. We recommend that KMeans not serve as the main mode for analysis but a verification step. The other result that this analysis gives us is the agreement between methods. The only thing that changes with the increasing k values is the number of clusters in the KMeans algorithm. That means that when doing these comparisons, we are also checking to see whether the other methods have a consistent level of agreement with one another as we are just training it with a different training set. This can be considered an extension of cross-validation where we are checking consistency. The Logistic Regression method and the Linear SVM have the highest level of agreement across the board. This is not unexpected because the Logistic Regression Method uses the OneVsRestClassifier algorithm when the classification becomes a multiclass problem. The scoring here reflects that commonality between then. Looking across the board, these methods don't individuall agree very well with one another (e.g. Log. Reg. and RFC only have a 0.45 average rand index, which is not very good). This could be because of the noise associated with the _Control_ and _Follow_ patients. Overall though, these numbers verify consistency in our methods.\n",
    "\n",
    "| Methods Being Compared  | k = 2 | k = 3 | k = 4 | k = 5 | k = 6 |  k = 7 | k = 8 | k = 9 | k = 10 |\n",
    "|-------------------------|-------|-------|-------|-------|-------|--------|-------|-------|--------|\n",
    "| Log. Reg. and RFC       | 0.42  | 0.47  | 0.47  | 0.47  | 0.49  | 0.45   | 0.52  | 0.43  | 0.50   |\n",
    "| Log. Reg. and KMeans    | -0.01 | 0.41  | 0.36  | 0.17  | 0.19  | 0.14   | 0.14  | 0.13  | 0.13   |\n",
    "| Log. Reg. and Lin. SVM. | 0.81  | 0.82  | 0.85  | 0.83  | 0.84  | 0.83   | 0.83  | 0.82  | 0.84   |\n",
    "| RFC and KMeans          | -0.01 | 0.23  | 0.22  | 0.12  | 0.16  | 0.12   | 0.13  | 0.11  | 0.11   |\n",
    "| RFC and Lin. SVM        | 0.41  | 0.46  | 0.45  | 0.42  | 0.45  | 0.42   | 0.48  | 0.42  | 0.49   |\n",
    "| KMeans and Lin. SVM     | -0.00 | 0.40  | 0.34  | 0.15  | 0.17  | 0.13   | 0.13  | 0.12  | 0.12   |\n",
    "\n",
    "```\n",
    "Table 1. Summary of comparisons between different methods for varying numbers of clusters used in KMeans Algorithm.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations and Future Direction\n",
    "\n",
    "Based on our results here, we cannot indicate which method is the best for making these kinds of predictions. Each method offers something useful and unique to our analysis. Random Forest gave us a breakdown of the feature importances, which aligned with the expectations we derived from the literature. However, it also had the lowest AUC compared to the other methods. We propose as a potential future directino the combination of the Random Forest classifier, the Linear SVM, and the Logistic Regression models into an ensemble method where we take characteristics and qualities from each and use it to build a more robust package for conducting these kinds of microbiome analyses. Furthermore, we have shown that these methods are applicable to microbiome problems and can be adapted to answer a variety of questions. The limitations as it stand are largely determined by the nature of the experimental data. For instance, here, we saw that the ambiguity amongts _Follow_ patients lead to a redcued AUC score. Any semblance of noise or inconsistency in the experimental data can lead to reduced performances of these models and thus require further adjustments. The benefits to making this investment come in the form of time and money. This analysis pipeline can be implemented quickly and effectively (as shown below by our code), and does not require laborious by-hand work to be done beforehand. It also saves money in regards to accurately identifying the \"at risk\" patients very well, which mean we are reducing the amount of money wasted on asking for expert opinion or for a cinician's time to see a patient. The applications that machine learning has at its disposal are vast, and continued work in creating these robust models and formulating many together into an ensemble could lead to leaps in medical diagnosis and research alike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1.    \tHall AJ, Rosenthal M, Gregoricus N, Greene SA, Ferguson J, Henao OL, Vinjé J, Lopman BA, Parashar UD, Widdowson MA. 2011. Incidence of acute gastroenteritis and role of norovirus, Georgia, USA, 2004-2005. Emerg Infect Dis 17:1381–1388.\n",
    "2.    \tFletcher SM, Stark D, Ellis J. 2011. Prevalence of gastrointestinal pathogens in Sub-Saharan Africa: systematic review and meta-analysis. J Public health Res 2:e30.\n",
    "3.    \tBraun T, Di Segni A, BenShoshan M, Asaf R, Squires JE, Farage Barhom S, Glick Saar E, Cesarkas K, Smollan G, Weiss B, Amit S, Keller N, Haberman Y. 2017. Fecal microbial characterization of hospitalized patients with suspected infectious diarrhea shows significant dysbiosis. Sci Rep 7:1088.\n",
    "4.    \tConsortium THMP. 2013. Structure, Function and Diversity of the Healthy Human Microbiome. Nature 486:207–214.\n",
    "5.    \tSingh P, Teal TK, Marsh TL, Tiedje JM, Mosci R, Jernigan K, Zell A, Newton DW, Salimnia H, Lephart P, Sundin D, Khalife W, Britton RA, Rudrik JT, Manning SD. 2015. Intestinal microbial communities associated with acute enteric infections and disease recovery. Microbiome 3:45.\n",
    "6.    \tGanji L, Alebouyeh M, Shirazi MH, Eshraghi SS, Mirshafiey A, Ebrahimi Daryani N, Zali MR. 2016. Dysbiosis of fecal microbiota and high frequency of Citrobacter, Klebsiella spp., and Actinomycetes in patients with irritable bowel syndrome and gastroenteritis. Gastroenterol Hepatol from bed to bench 9:325–330.\n",
    "7.    \tChen S-Y, Tsai C-N, Lee Y-S, Lin C-Y, Huang K-Y, Chao H-C, Lai M-W, Chiu C-H. 2017. Intestinal microbiome in children with severe and complicated acute viral gastroenteritis. Sci Rep 7:46130.\n",
    "8.    \tSmall CL, Xing L, McPhee JB, Law HT, Coombes BK. 2016. Acute Infectious Gastroenteritis Potentiates a Crohn’s Disease Pathobiont to Fuel Ongoing Inflammation in the Post-Infectious Period. PLoS Pathog 12:1–20.\n",
    "9.    \tJangi S, Gandhi R, Cox LM, Li N, von Glehn F, Yan R, Patel B, Mazzola MA, Liu S, Glanz BL, Cook S, Tankou S, Stuart F, Melo K, Nejad P, Smith K, Topçuolu BD, Holden J, Kivisäkk P, Chitnis T, De Jager PL, Quintana FJ, Gerber GK, Bry L, Weiner HL. 2016. Alterations of the human gut microbiome in multiple sclerosis. Nat Commun 7:12015.\n",
    "10.  \tDi Paola M, Cavalieri D, Albanese D, Sordo M, Pindo M, Donati C, Pagnini I, Giani T, Simonini G, Paladini A, Lionetti P, De Filippo C, Cimaz R. 2016. Alteration of fecal microbiota profiles in juvenile idiopathic arthritis. Associations with hla-b27 allele and disease status. Front Microbiol 7:1–13.\n",
    "11.  \tMu Q, Kirby J, Reilly CM, Luo XM. 2017. Leaky Gut As a Danger Signal for Autoimmune Diseases. Front Immunol 8:598.\n",
    "12.  \tRigoni R, Fontana E, Guglielmetti S, Fosso B, D’Erchia AM, Maina V, Taverniti V, Castiello MC, Mantero S, Pacchiana G, Musio S, Pedotti R, Selmi C, Mora JR, Pesole G, Vezzoni P, Poliani PL, Grassi F, Villa A, Cassani B. 2016. Intestinal microbiota sustains inflammation and autoimmunity induced by hypomorphic RAG defects. J Exp Med 213:355–375.\n",
    "13.  \tDegruttola AK, Low D, Mizoguchi A, Mizoguchi E. 2016. Current understanding of dysbiosis in disease in human and animal models 22:1137–1150.\n",
    "14.  \tPasolli E, Truong DT, Malik F, Waldron L, Segata N. 2016. Machine Learning Meta-analysis of Large Metagenomic Datasets: Tools and Biological Insights. PLoS Comput Biol 12.\n",
    "15.  \tOlson. 2017. Data-driven Advice for Applying Machine Learning to Bioinformatics Problems. World Scientific Publishing Company.\n",
    "16.  \tSvetnik V, Liaw A, Tong C, Christopher Culberson J, Sheridan RP, Feuston BP. 2003. Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling. J Chem Inf Comput Sci 43:1947–1958.\n",
    "17.  \tIllumina. 2015. An Introduction to Next-Generation Sequencing Technology. Illumina.com 1–16.\n",
    "18.  \tRho M, Tang H, Ye Y. 2010. FragGeneScan: Predicting genes in short and error-prone reads. Nucleic Acids Res 38.\n",
    "19.  \tLi W, Godzik A. 2006. Cd-hit: A fast program for clustering and comparing large sets of protein or nucleotide sequences. Bioinformatics 22:1658–1659.\n",
    "20.  \tBolger a. M, Lohse M, Usadel B. 2014. Trimmomatic: A flexible read trimming tool for Illumina NGS data. Bioinformatics 30:2114–2120.\n",
    "21.  \tAndrews S. 2010. FastQC: A quality control tool for high throughput sequence data. Http://WwwBioinformaticsBabrahamAcUk/Projects/Fastqc/.\n",
    "22.  \tLangmead B, Salzberg SL. 2012. Fast gapped-read alignment with Bowtie 2. Nat Methods 9:357–9.\n",
    "23.  \tLi H, Handsaker B, Wysoker A, Fennell T, Ruan J, Homer N, Marth G, Abecasis G, Durbin R. 2009. The Sequence Alignment / Map (SAM) Format and SAMtools 1000 Genome Project Data Processing Subgroup. Bioinformatics 25:1–2.\n",
    "24.  \tPeng Y, Leung HCM, Yiu SM, Chin FYL. 2012. IDBA-UD: A de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth. Bioinformatics 28:1420–1428.\n",
    "25.  \tLi H. 2010. Aligning new-sequencing reads by BWA BWA : Burrows-Wheeler Aligner. PPT.\n",
    "26.  \tAltschul SF. 2014. BLAST Algorithm. eLS 1–4.\n",
    "27.  \tPruitt K, Brown G, Tatusova T, Maglott D. 2002. The Reference Sequence ( RefSeq ) Database. NCBI Handb 1–24.\n",
    "28.  \tHuson DH, Beier S, Flade I, G??rska A, El-Hadidi M, Mitra S, Ruscheweyh HJ, Tappu R. 2016. MEGAN Community Edition - Interactive Exploration and Analysis of Large-Scale Microbiome Sequencing Data. PLoS Comput Biol 12.\n",
    "29.  \tWood DE, Salzberg SL. 2014. Kraken: Ultrafast metagenomic sequence classification using exact alignments. Genome Biol 15.\n",
    "30.  \tWarton DI, Wright ST, Wang Y. 2012. Distance-based multivariate analyses confound location and dispersion effects. Methods Ecol Evol 3:89–101.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Overview\n",
    "\n",
    "1. imports the microbiome and clinical data\n",
    "2. normalizes the microbiome data with log-transformation and Z-score (a standard appraoch)\n",
    "3. performs a Random Forest Classifier, Linear Support Vector Machine, Logistic Regression, Kmeans\n",
    "4. Calculates AUC of above 4 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing necessary libraries\n"
     ]
    }
   ],
   "source": [
    "##Imports\n",
    "print(\"Importing necessary libraries\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import zscore\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Sklearn Imports\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##Print Message Function and Plot Confusion Matrix\n",
    "##########################################################\n",
    "def print_message(string):\n",
    "    print('#'*(len(string) + 2))\n",
    "    print('#'+string+'#')\n",
    "    print('#'*(len(string) + 2))\n",
    "\n",
    "##From sklearn\n",
    "##http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, fname = \"\"):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname)\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading in the Data\n",
      "Transforming classes into integers for the model\n",
      "Getting the bacterial/viral counts from the data and clinical symptoms\n",
      "\n",
      "Getting feature names from data\n",
      "#########################\n",
      "#Data Loaded and Ready!!#\n",
      "#########################\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnoho\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log2\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "##Loading, Concaetnating, and Cleaning the Data for Analysis\n",
    "##########################################################\n",
    "\n",
    "##Load in data\n",
    "print(\"\\n\\nLoading in the Data\")\n",
    "# data_df = pd.read_csv(\"full_data.csv\")\n",
    "data_df = pd.read_csv(\"full_data.csv\") ##Local Development Copy\n",
    "\n",
    "##Extract Class Predictions and make them discrete integers\n",
    "print(\"Transforming classes into integers for the model\")\n",
    "labels = data_df['Health'].values\n",
    "unique_labs = np.unique(labels)\n",
    "y_true = []\n",
    "for i in labels:\n",
    "    y_true.append([j for j in range(len(unique_labs)) if unique_labs[j] == i][0])\n",
    "\n",
    "##Extract the indices for the tags for the bacterial/viral data\n",
    "print(\"Getting the bacterial/viral counts from the data and clinical symptoms\\n\")\n",
    "first_tag = 'Bacteroidetes'\n",
    "last_tag = 'Virus'\n",
    "first_loc = [x for x in range(len(data_df.columns)) if data_df.columns[x] == first_tag][0]\n",
    "last_loc = [x+1 for x in range(len(data_df.columns)) if data_df.columns[x] == last_tag][0]\n",
    "\n",
    "##Get the names of those features from the data\n",
    "print(\"Getting feature names from data\")\n",
    "micro_bio_colums = data_df.columns[first_loc:last_loc]\n",
    "\n",
    "##Getting the clinical columns\n",
    "first_tag = 'No Symptoms'\n",
    "last_tag = 'Fever'\n",
    "first_loc = [x for x in range(len(data_df.columns)) if data_df.columns[x] == first_tag][0]\n",
    "last_loc = [x+1 for x in range(len(data_df.columns)) if data_df.columns[x] == last_tag][0]\n",
    "clinical_columns = data_df.columns[first_loc:last_loc]\n",
    "\n",
    "##Extract the matrix of expression data and normalize\n",
    "##Log2 transform and the z-score normalization\n",
    "micro_bio_data = data_df[micro_bio_colums].values.astype(float)\n",
    "micro_bio_data = np.log2(micro_bio_data)\n",
    "micro_bio_data[np.isnan(micro_bio_data)] = 0\n",
    "micro_bio_data[np.isinf(micro_bio_data)] = 0\n",
    "micro_bio_data = zscore(micro_bio_data, axis = 1)\n",
    "micro_bio_data[np.isnan(micro_bio_data)] = 0\n",
    "clincal_data = data_df[clinical_columns].values.astype(float)\n",
    "\n",
    "##Total Features\n",
    "features = np.array(list(clinical_columns)+list(micro_bio_colums))\n",
    "\n",
    "##Final Model Data\n",
    "X = np.concatenate((clincal_data,micro_bio_data), axis = 1)\n",
    "y = y_true\n",
    "\n",
    "print_message(\"Data Loaded and Ready!!\")\n",
    "##########################################################\n",
    "##########################################################\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Health</th>\n",
       "      <th>No Symptoms</th>\n",
       "      <th>Abdominal Pain</th>\n",
       "      <th>Body Ache</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Diarrhea w/Blood</th>\n",
       "      <th>Chills</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Headache</th>\n",
       "      <th>...</th>\n",
       "      <th>Dictyoglomi</th>\n",
       "      <th>Elusimicrobia</th>\n",
       "      <th>Deferribacteres</th>\n",
       "      <th>Chrysiogenetes</th>\n",
       "      <th>Gemmatimonadetes</th>\n",
       "      <th>Armatimonadetes</th>\n",
       "      <th>Candidatus Saccharibacteria</th>\n",
       "      <th>Thermodesulfobacteria</th>\n",
       "      <th>Caldiserica</th>\n",
       "      <th>Virus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Case</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Case</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Follow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample ID   Health  No Symptoms  Abdominal Pain  Body Ache  Diarrhea  \\\n",
       "0          1     Case            0               0          0         1   \n",
       "1          2     Case            0               1          0         1   \n",
       "2          4     Case            0               1          0         1   \n",
       "3          6  Control            0               0          0         1   \n",
       "4          7   Follow            1               0          0         0   \n",
       "\n",
       "   Diarrhea w/Blood  Chills  Fatigue  Headache  ...    Dictyoglomi  \\\n",
       "0                 0       0        0         0  ...              0   \n",
       "1                 1       1        1         0  ...              0   \n",
       "2                 1       0        0         0  ...              0   \n",
       "3                 0       0        0         0  ...              0   \n",
       "4                 0       0        0         0  ...              0   \n",
       "\n",
       "   Elusimicrobia  Deferribacteres  Chrysiogenetes  Gemmatimonadetes  \\\n",
       "0              0                0               0                 0   \n",
       "1              0                0               0                 0   \n",
       "2              0                0               0                 0   \n",
       "3              0                0               0                 0   \n",
       "4              0                0               0                 0   \n",
       "\n",
       "   Armatimonadetes  Candidatus Saccharibacteria  Thermodesulfobacteria  \\\n",
       "0                0                            0                      0   \n",
       "1                0                            0                      0   \n",
       "2                0                            0                      0   \n",
       "3                0                            0                      0   \n",
       "4                0                            0                      0   \n",
       "\n",
       "   Caldiserica  Virus  \n",
       "0            0   2620  \n",
       "1            0    442  \n",
       "2            0    433  \n",
       "3            0   2537  \n",
       "4            0   2007  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataframe\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################\n",
      "#Working on RFC#\n",
      "################\n",
      "Confusion matrix, without normalization\n",
      "[[15  1  2]\n",
      " [ 1 25  1]\n",
      " [ 1  4  4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.86        18\n",
      "          1       0.83      0.93      0.88        27\n",
      "          2       0.57      0.44      0.50         9\n",
      "\n",
      "avg / total       0.81      0.81      0.81        54\n",
      "\n",
      "##########################\n",
      "#Random Forest Classifier#\n",
      "##########################\n",
      "\n",
      "After 20 Trials:\n",
      "AUC Case: 0.9221\n",
      "AUC Control: 0.8316\n",
      "AUC Follow: 0.7784\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "##Random Forest Classifier\n",
    "##########################################################\n",
    "\n",
    "##Make dictionary to store model importances\n",
    "print_message(\"Working on RFC\")\n",
    "\n",
    "model_importances = {}\n",
    "for feature in list(clinical_columns)+list(micro_bio_colums):\n",
    "    model_importances[feature] = 0\n",
    "\n",
    "##Store AUC for CV\n",
    "auc_validations = {}\n",
    "for k in np.unique(y_true):\n",
    "    auc_validations[k] = []\n",
    "\n",
    "##K-fold Cross Validation\n",
    "for T in range(20):\n",
    "    ##Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = TTS(X, y, test_size = 0.25)\n",
    "\n",
    "    ##Train the Model\n",
    "    # print(\"Building RFC model\\n\")\n",
    "    rfc = RFC(n_estimators=30, n_jobs = 5)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict_proba(X_test)\n",
    "    y_pred_b = rfc.predict(X_test)\n",
    "\n",
    "    ##Create encoding for AUC\n",
    "    y_test_e = label_binarize(y_test, classes = np.unique(y_test))\n",
    "\n",
    "    # Compute ROC Curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(y_test_e.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_e[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    for k in roc_auc.keys():\n",
    "        auc_validations[k].append(roc_auc[k])\n",
    "\n",
    "\n",
    "    ##Extract Feature Importances\n",
    "    importances = rfc.feature_importances_\n",
    "    sorted_inds = np.argsort(importances)[::-1]\n",
    "    sorted_features = features[sorted_inds]\n",
    "    sorted_importances = importances[sorted_inds]\n",
    "\n",
    "    for i,val in enumerate(sorted_features):\n",
    "        model_importances[val] += sorted_importances[i]\n",
    "\n",
    "    if T==19:\n",
    "        rfc = plot_confusion_matrix(confusion_matrix(y_test, y_pred_b), classes = [\"Sick\", \"Healthy\", \"Follow\"], fname = r\"results/random_forest.png\")\n",
    "        print(confusion_matrix(y_test, y_pred_b))\n",
    "        print(classification_report(y_test, y_pred_b))\n",
    "\n",
    "\n",
    "##Print Results for Random Forest\n",
    "print_message(\"Random Forest Classifier\")\n",
    "print('\\n'+\"After {} Trials:\".format(T+1))\n",
    "for k in auc_validations.keys():\n",
    "    print(\"AUC {}: {}\".format(unique_labs[k], round(np.mean(auc_validations[k]),4)))\n",
    "\n",
    "##Final Feature Importances Plot\n",
    "importances = np.array(list(model_importances.values()))\n",
    "sorted_inds = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[sorted_inds]/len(importances)\n",
    "features = np.array(list(model_importances.keys()))\n",
    "sorted_features = features[sorted_inds]\n",
    "plt.figure(figsize=(13, 7))\n",
    "ax = plt.gca()\n",
    "ax.bar(range(len(sorted_inds)), sorted_importances)\n",
    "ax.set_title(\"Feature Importances\", fontsize = 23)\n",
    "ax.set_ylabel(\"Feature Importances\", fontsize = 16)\n",
    "ax.set_xlabel(\"Feature\", fontsize = 16)\n",
    "ax.set_xticks(range(len(sorted_inds)))\n",
    "ax.set_xticklabels(sorted_features, rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"results/full_w_clinical_importances.png\", dpi = 200, bbox_inches = 'tight')\n",
    "\n",
    "to_save = np.array(importances)\n",
    "np.savetxt(r\"results/importances_in_order_of_features.txt\", to_save)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#Working on Linear Support Vector Machine#\n",
      "##########################################\n",
      "Confusion matrix, without normalization\n",
      "[[13  1  1]\n",
      " [ 1 25  2]\n",
      " [ 0  4  7]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.87      0.90        15\n",
      "          1       0.83      0.89      0.86        28\n",
      "          2       0.70      0.64      0.67        11\n",
      "\n",
      "avg / total       0.83      0.83      0.83        54\n",
      "\n",
      "############\n",
      "#Linear SVM#\n",
      "############\n",
      "\n",
      "After 20 Trials:\n",
      "AUC Case: 0.95\n",
      "AUC Control: 0.8793\n",
      "AUC Follow: 0.8378\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "##Linear SVM\n",
    "##########################################################\n",
    "print_message(\"Working on Linear Support Vector Machine\")\n",
    "\n",
    "##Store AUC for CV\n",
    "auc_validations = {}\n",
    "for k in np.unique(y_true):\n",
    "    auc_validations[k] = []\n",
    "\n",
    "##Cross Validation by Repeat Trials\n",
    "for T in range(20):\n",
    "    # print(\"Trial {}\".format(T+1))\n",
    "    ##Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = TTS(X, y, test_size = 0.25)\n",
    "\n",
    "    ##Train the Model\n",
    "    classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict_proba(X_test)\n",
    "    y_pred_b = classifier.predict(X_test)\n",
    "\n",
    "    ##Create encoding for AUC\n",
    "    y_test_e = label_binarize(y_test, classes = np.unique(y_true))\n",
    "\n",
    "    # Compute ROC Curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(y_test_e.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_e[:,i], y_pred[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    for k in roc_auc.keys():\n",
    "        auc_validations[k].append(roc_auc[k])\n",
    "\n",
    "    if T==19:\n",
    "        lin_reg = plot_confusion_matrix(confusion_matrix(y_test, y_pred_b), classes = [\"Sick\", \"Healthy\", \"Follow\"], fname = r\"results/lin_svm.png\")\n",
    "        print(confusion_matrix(y_test, y_pred_b))\n",
    "        print(classification_report(y_test, y_pred_b))\n",
    "\n",
    "##Print Results\n",
    "print_message(\"Linear SVM\")\n",
    "print('\\n'+\"After {} Trials:\".format(T+1))\n",
    "for k in auc_validations.keys():\n",
    "    print(\"AUC {}: {}\".format(unique_labs[k], round(np.mean(auc_validations[k]),4)))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################\n",
      "#Working on Logistic Regression#\n",
      "################################\n",
      "Confusion matrix, without normalization\n",
      "[[13  1  2]\n",
      " [ 1 18  5]\n",
      " [ 0  1 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.87        16\n",
      "          1       0.90      0.75      0.82        24\n",
      "          2       0.65      0.93      0.76        14\n",
      "\n",
      "avg / total       0.84      0.81      0.82        54\n",
      "\n",
      "#####################\n",
      "#Logistic Regression#\n",
      "#####################\n",
      "\n",
      "After 20 Trials:\n",
      "AUC Case: 0.9525\n",
      "AUC Control: 0.8819\n",
      "AUC Follow: 0.8503\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "##Logistic Regression\n",
    "##########################################################\n",
    "print_message(\"Working on Logistic Regression\")\n",
    "\n",
    "##Store AUC for CV\n",
    "auc_validations = {}\n",
    "for k in np.unique(y_true):\n",
    "    auc_validations[k] = []\n",
    "\n",
    "##Cross Validation by Repeat Trials\n",
    "for T in range(20):\n",
    "    ##Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = TTS(X, y, test_size = 0.25)\n",
    "\n",
    "    ##Train the Model\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict_proba(X_test)\n",
    "    y_pred_b = classifier.predict(X_test)\n",
    "\n",
    "    ##Create encoding for AUC\n",
    "    y_test_e = label_binarize(y_test, classes = np.unique(y_true))\n",
    "\n",
    "    # Compute ROC Curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(y_test_e.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_e[:,i], y_pred[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    for k in roc_auc.keys():\n",
    "        if roc_auc[k] != np.nan:\n",
    "            auc_validations[k].append(roc_auc[k])\n",
    "\n",
    "    if T==19:\n",
    "        log_reg = plot_confusion_matrix(confusion_matrix(y_test, y_pred_b), classes = [\"Sick\", \"Healthy\", \"Follow\"], fname = r\"results/log_reg.png\")\n",
    "        print(confusion_matrix(y_test, y_pred_b))\n",
    "        print(classification_report(y_test, y_pred_b))\n",
    "\n",
    "##Print Results\n",
    "print_message(\"Logistic Regression\")\n",
    "print('\\n'+\"After {} Trials:\".format(T+1))\n",
    "for k in auc_validations.keys():\n",
    "    print(\"AUC {}: {}\".format(unique_labs[k], round(np.mean(auc_validations[k]),4)))\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################\n",
      "#Comparison Results for K=2#\n",
      "############################\n",
      "Result for K = 2\n",
      "Log,RFC: 0.4208\n",
      "Log,KMeans: -0.0141\n",
      "Log,Lin: 0.8131\n",
      "RFC,KMeans: -0.0122\n",
      "RFC,Lin: 0.4067\n",
      "KMeans,Lin: -0.006\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=3#\n",
      "############################\n",
      "Result for K = 3\n",
      "Log,RFC: 0.4771\n",
      "Log,KMeans: 0.4106\n",
      "Log,Lin: 0.8221\n",
      "RFC,KMeans: 0.2265\n",
      "RFC,Lin: 0.4567\n",
      "KMeans,Lin: 0.3951\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=4#\n",
      "############################\n",
      "Result for K = 4\n",
      "Log,RFC: 0.4771\n",
      "Log,KMeans: 0.3626\n",
      "Log,Lin: 0.8488\n",
      "RFC,KMeans: 0.2208\n",
      "RFC,Lin: 0.448\n",
      "KMeans,Lin: 0.3367\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=5#\n",
      "############################\n",
      "Result for K = 5\n",
      "Log,RFC: 0.4745\n",
      "Log,KMeans: 0.1707\n",
      "Log,Lin: 0.8251\n",
      "RFC,KMeans: 0.1215\n",
      "RFC,Lin: 0.4245\n",
      "KMeans,Lin: 0.1548\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=6#\n",
      "############################\n",
      "Result for K = 6\n",
      "Log,RFC: 0.4911\n",
      "Log,KMeans: 0.1917\n",
      "Log,Lin: 0.8384\n",
      "RFC,KMeans: 0.1625\n",
      "RFC,Lin: 0.4509\n",
      "KMeans,Lin: 0.1728\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=7#\n",
      "############################\n",
      "Result for K = 7\n",
      "Log,RFC: 0.4489\n",
      "Log,KMeans: 0.1446\n",
      "Log,Lin: 0.8327\n",
      "RFC,KMeans: 0.1235\n",
      "RFC,Lin: 0.4218\n",
      "KMeans,Lin: 0.1284\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=8#\n",
      "############################\n",
      "Result for K = 8\n",
      "Log,RFC: 0.5244\n",
      "Log,KMeans: 0.1407\n",
      "Log,Lin: 0.8295\n",
      "RFC,KMeans: 0.1298\n",
      "RFC,Lin: 0.4819\n",
      "KMeans,Lin: 0.1331\n",
      "\n",
      "\n",
      "############################\n",
      "#Comparison Results for K=9#\n",
      "############################\n",
      "Result for K = 9\n",
      "Log,RFC: 0.4326\n",
      "Log,KMeans: 0.1395\n",
      "Log,Lin: 0.8211\n",
      "RFC,KMeans: 0.1122\n",
      "RFC,Lin: 0.423\n",
      "KMeans,Lin: 0.123\n",
      "\n",
      "\n",
      "#############################\n",
      "#Comparison Results for K=10#\n",
      "#############################\n",
      "Result for K = 10\n",
      "Log,RFC: 0.5036\n",
      "Log,KMeans: 0.1329\n",
      "Log,Lin: 0.8433\n",
      "RFC,KMeans: 0.1054\n",
      "RFC,Lin: 0.4945\n",
      "KMeans,Lin: 0.1231\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "##Comaprison to Methods\n",
    "##########################################################\n",
    "##K to try\n",
    "ks = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "##Run pca take first 5 principle components\n",
    "X = PCA(n_components = 5).fit_transform(X)\n",
    "\n",
    "for K in ks:\n",
    "\n",
    "    ##Store Adjusted Rand Indices\n",
    "    rand_indexes = {\"Log,RFC\":0, \"Log,KMeans\":0, \"Log,Lin\":0, \"RFC,KMeans\":0, \"RFC,Lin\":0, \"KMeans,Lin\":0}\n",
    "\n",
    "    print_message(\"Comparison Results for K={}\".format(K))\n",
    "\n",
    "    ##Cross Validation by Repeat Trials\n",
    "    cnt = 1\n",
    "    for T in range(20):\n",
    "\n",
    "        ##Train-Test Split\n",
    "        X_train, X_test, y_train, y_test = TTS(X, y, test_size = 0.25)\n",
    "\n",
    "        ##Logistic Regression\n",
    "        lr_classifier = LogisticRegression()\n",
    "        y_pred_log = lr_classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "        ##Random Forest\n",
    "        rfc = RFC(n_estimators=30, n_jobs = 5)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        y_pred_rf = rfc.predict(X_test)\n",
    "\n",
    "        ##KMeans\n",
    "        ##Assigns new data to the nearest centroid\n",
    "        kmeans = KMeans(n_clusters = K)\n",
    "        kmeans.fit(X_train, y_train)\n",
    "        y_pred_km = kmeans.predict(X_test)\n",
    "\n",
    "        ##Linear SVM\n",
    "        classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "        y_pred_lin = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "        rand_indexes[\"Log,RFC\"] += adjusted_rand_score(y_pred_log, y_pred_rf)\n",
    "        rand_indexes[\"Log,KMeans\"] += adjusted_rand_score(y_pred_log, y_pred_km)\n",
    "        rand_indexes[\"Log,Lin\"] += adjusted_rand_score(y_pred_log, y_pred_lin)\n",
    "        rand_indexes[\"RFC,KMeans\"] += adjusted_rand_score(y_pred_rf, y_pred_km)\n",
    "        rand_indexes[\"RFC,Lin\"] += adjusted_rand_score(y_pred_rf, y_pred_lin)\n",
    "        rand_indexes[\"KMeans,Lin\"] += adjusted_rand_score(y_pred_km, y_pred_lin)\n",
    "        cnt += 1\n",
    "\n",
    "    ##Print Result\n",
    "    print(\"Result for K = {}\".format(K))\n",
    "    for key in rand_indexes.keys():\n",
    "        print(\"{}: {}\".format(key, round(rand_indexes[key]/cnt, 4)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "##########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
